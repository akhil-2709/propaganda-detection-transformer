2022-05-11 18:56:10,890 INFO    MainThread:73 [wandb_setup.py:_flush():76] Loading settings from /root/.config/wandb/settings
2022-05-11 18:56:10,891 INFO    MainThread:73 [wandb_setup.py:_flush():76] Loading settings from /content/drive/MyDrive/685-NLP_Project/wandb/settings
2022-05-11 18:56:10,891 INFO    MainThread:73 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2022-05-11 18:56:10,891 INFO    MainThread:73 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2022-05-11 18:56:10,891 INFO    MainThread:73 [wandb_setup.py:_flush():76] Applying login settings: {'api_key': '***REDACTED***'}
2022-05-11 18:56:10,891 INFO    MainThread:73 [wandb_init.py:_log_setup():428] Logging user logs to /content/drive/MyDrive/685-NLP_Project/wandb/run-20220511_185610-n559ysys/logs/debug.log
2022-05-11 18:56:10,892 INFO    MainThread:73 [wandb_init.py:_log_setup():429] Logging internal logs to /content/drive/MyDrive/685-NLP_Project/wandb/run-20220511_185610-n559ysys/logs/debug-internal.log
2022-05-11 18:56:10,892 INFO    MainThread:73 [wandb_init.py:_jupyter_setup():378] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f4575129c90>
2022-05-11 18:56:10,892 INFO    MainThread:73 [wandb_init.py:init():462] calling init triggers
2022-05-11 18:56:10,893 INFO    MainThread:73 [wandb_init.py:init():466] wandb.init called with sweep_config: {}
config: {'adafactor_beta1': None, 'adafactor_clip_threshold': 1.0, 'adafactor_decay_rate': -0.8, 'adafactor_eps': (1e-30, 0.001), 'adafactor_relative_step': False, 'adafactor_scale_parameter': False, 'adafactor_warmup_init': False, 'adam_epsilon': 1e-08, 'best_model_dir': 'outputs/best_model', 'cache_dir': 'cache_dir/', 'config': {}, 'cosine_schedule_num_cycles': 0.5, 'custom_layer_parameters': [], 'custom_parameter_groups': [], 'dataloader_num_workers': 0, 'do_lower_case': False, 'dynamic_quantize': False, 'early_stopping_consider_epochs': False, 'early_stopping_delta': 0, 'early_stopping_metric': 'eval_loss', 'early_stopping_metric_minimize': True, 'early_stopping_patience': 3, 'encoding': None, 'eval_batch_size': 64, 'evaluate_during_training': True, 'evaluate_during_training_silent': True, 'evaluate_during_training_steps': 15000, 'evaluate_during_training_verbose': True, 'evaluate_each_epoch': True, 'fp16': False, 'gradient_accumulation_steps': 1, 'learning_rate': 0.001, 'local_rank': -1, 'logging_steps': 50, 'loss_type': None, 'loss_args': {}, 'manual_seed': None, 'max_grad_norm': 1.0, 'max_seq_length': 196, 'model_name': 't5-base', 'model_type': 't5', 'multiprocessing_chunksize': -1, 'n_gpu': 1, 'no_cache': False, 'no_save': False, 'not_saved_args': [], 'num_train_epochs': 10, 'optimizer': 'Adafactor', 'output_dir': 'outputs/', 'overwrite_output_dir': True, 'polynomial_decay_schedule_lr_end': 1e-07, 'polynomial_decay_schedule_power': 1.0, 'process_count': 1, 'quantized_model': False, 'reprocess_input_data': True, 'save_best_model': True, 'save_eval_checkpoints': False, 'save_model_every_epoch': False, 'save_optimizer_and_scheduler': True, 'save_steps': -1, 'scheduler': 'constant_schedule_with_warmup', 'silent': False, 'skip_special_tokens': True, 'tensorboard_dir': None, 'thread_count': None, 'tokenizer_name': None, 'tokenizer_type': None, 'train_batch_size': 4, 'train_custom_parameters_only': False, 'use_cached_eval_features': False, 'use_early_stopping': False, 'use_hf_datasets': False, 'use_multiprocessing': False, 'use_multiprocessing_for_evaluation': True, 'wandb_kwargs': {}, 'wandb_project': 'T5 mixed tasks - Binary, Multi-Label, Regression', 'warmup_ratio': 0.06, 'warmup_steps': 93, 'weight_decay': 0.0, 'model_class': 'T5Model', 'dataset_class': None, 'do_sample': False, 'early_stopping': True, 'evaluate_generated_text': False, 'length_penalty': 2.0, 'max_length': 20, 'max_steps': -1, 'num_beams': 1, 'num_return_sequences': 1, 'preprocess_inputs': True, 'repetition_penalty': 1.0, 'special_tokens_list': [], 'top_k': None, 'top_p': None, 'use_multiprocessed_decoding': True}
2022-05-11 18:56:10,893 INFO    MainThread:73 [wandb_init.py:init():515] starting backend
2022-05-11 18:56:10,893 INFO    MainThread:73 [backend.py:_multiprocessing_setup():99] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2022-05-11 18:56:10,939 INFO    MainThread:73 [backend.py:ensure_launched():217] starting backend process...
2022-05-11 18:56:10,987 INFO    MainThread:73 [backend.py:ensure_launched():222] started backend process with pid: 538
2022-05-11 18:56:10,992 INFO    MainThread:73 [wandb_init.py:init():525] backend started and connected
2022-05-11 18:56:11,065 INFO    MainThread:73 [wandb_run.py:_label_probe_notebook():1089] probe notebook
2022-05-11 18:56:14,968 INFO    MainThread:73 [wandb_init.py:init():596] updated telemetry
2022-05-11 18:56:14,973 INFO    MainThread:73 [wandb_init.py:init():628] communicating run to backend with 30 second timeout
2022-05-11 18:56:15,297 INFO    MainThread:73 [wandb_run.py:_on_init():1924] communicating current version
2022-05-11 18:56:15,329 INFO    MainThread:73 [wandb_run.py:_on_init():1928] got version response 
2022-05-11 18:56:15,330 INFO    MainThread:73 [wandb_init.py:init():662] starting run threads in backend
2022-05-11 18:56:17,736 INFO    MainThread:73 [wandb_run.py:_console_start():1898] atexit reg
2022-05-11 18:56:17,742 INFO    MainThread:73 [wandb_run.py:_redirect():1771] redirect: SettingsConsole.WRAP
2022-05-11 18:56:17,742 INFO    MainThread:73 [wandb_run.py:_redirect():1808] Wrapping output streams.
2022-05-11 18:56:17,749 INFO    MainThread:73 [wandb_run.py:_redirect():1832] Redirects installed.
2022-05-11 18:56:17,750 INFO    MainThread:73 [wandb_init.py:init():688] run started, returning control to user process
2022-05-11 18:56:17,750 INFO    MainThread:73 [wandb_watch.py:watch():47] Watching
2022-05-11 19:11:50,180 INFO    MainThread:73 [wandb_init.py:_pause_backend():341] pausing backend
2022-05-11 19:11:50,181 INFO    MainThread:73 [jupyter.py:save_ipynb():377] not saving jupyter notebook
